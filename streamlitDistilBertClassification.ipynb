{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MSEUese3Ly0"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit -q\n",
        "!pip install transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Xh4aRJD3NrS",
        "outputId": "c9b78583-3d38-411b-9418-439a49fe7a6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.106.154.190\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdCXdDNq3bX7",
        "outputId": "39da1922-78b6-4294-d3d8-e3904049b54f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import pipeline\n",
        "@st.cache_resource\n",
        "def model(input):\n",
        "  model = AutoModelForSequenceClassification.from_pretrained('mtolgakbabai16tr/distilbert-classification-model')\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"mtolgakbabai16tr/distilbert-classification-model\")\n",
        "  clf = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "  return clf(input)\n",
        "\n",
        "st.title('My AI App')\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "input = st.chat_input(\"write your text\")\n",
        "if input:\n",
        "  st.session_state.messages.append({\"role\": \"user\", \"content\": input})\n",
        "  with st.chat_message(\"user\"):\n",
        "      st.markdown(input)\n",
        "  with st.chat_message('assistant'):\n",
        "    output = model(input)\n",
        "  if int(output[0][\"label\"][-1]) == 1:\n",
        "    answer = \"beğeni\"\n",
        "  elif int(output[0][\"label\"][-1]) == 2:\n",
        "    answer = \"hata\"\n",
        "  elif int(output[0][\"label\"][-1]) == 3:\n",
        "    answer = \"diğer\"\n",
        "  else:\n",
        "    answer = \"eleştiri\"\n",
        "  st.session_state.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
        "  st.markdown(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3V046Hu3Prs",
        "outputId": "f1cf54e7-b439-4588-93c5-54fdf5483ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.106.154.190:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.307s\n",
            "your url is: https://tiny-eels-lie.loca.lt\n",
            "2024-07-12 08:28:42.627641: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-12 08:28:42.627699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-12 08:28:42.629234: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-12 08:28:42.638484: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-12 08:28:44.153246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}